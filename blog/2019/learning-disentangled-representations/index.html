<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Learning Disentangled Representations | Moksh Jain</title> <meta name="author" content="Moksh Jain"> <meta name="description" content="Moksh Jain. PhD Student in Machine Learning at Mila and UdeM. "> <meta name="keywords" content="representation-learning"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="../../../assets/css/main.css"> <link rel="canonical" href="index.html"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="../../../assets/js/theme.js"></script> <script src="../../../assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="../../../assets/js/distillpub/template.v2.js"></script> <script src="../../../assets/js/distillpub/transforms.v2.js"></script> <script src="../../../assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Learning Disentangled Representations",
      "description": "",
      "published": "July 10, 2019",
      "authors": [
        {
          "author": "Moksh Jain",
          "authorURL": "https://mj10.github.io/",
          "affiliations": [
            {
              "name": "Université de Montréal, Mila - Quebec AI Institute",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="../../../index.html">Moksh Jain</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="../../../index.html">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="../../index.html">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="../../../publications/index.html">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="../../../cv/index.html">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Learning Disentangled Representations</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <p><em>You can find the interactive notebook accompanying this article</em> <a href="https://colab.research.google.com/drive/1RPzxB9DZnQmoggIrwTk_c_8DdZqRXC2p" rel="external nofollow noopener" target="_blank"><strong>here</strong></a>.</p> <p>A <strong>representation</strong> in the most vague sense refers to the lower dimensional projection of some high-dimensional input. A good representation can then be defined as one that captures the relevant information required to describe the original high-dimensional data in a much more compact way (i.e \(num\_features\) « \(input\_dims\) ). There has been a lot of interest in the Machine Learning community to build models that can learn useful representations from high dimensional sensory inputs like audio, video, text, images, etc. These representations can then be used to have further models to perform useful tasks, like classifying images. The basic idea is having lower dimensional representations that can describe the original data is useful for models to extract more useful information than the original higher dimensional data. Representation Learning has become an important research area in the recent years. In their survey, <a href="https://arxiv.org/abs/1206.5538" rel="external nofollow noopener" target="_blank">Bengio et al.</a> talk about the need for representation learning and the latest developments in the area. According to the survey, informally, the goal of representation learning is to find useful transformations \(r(x)\) of the higher dimensional data \(x\) which makes it easier to extract useful information for various predictors. However, since the survey was published a lot of work has been done in this area, and one of the focuses has been of learning disentangled representations.</p> <h2 id="what-is-a-disentangled-representation">What is a disentangled representation?</h2> <p>One of the underlying asumptions in representation learning is that the high dimensional sensory data in the real world \(x\), like an image, is generated by a 2-step generative process. The first step is sampling a semantically meaningful latent variable \(z\) (from \(P(z)\)) that describes the high level information of the data, for example the location of a flower in the image, the color of the flower, it’s shape etc. The final step is to sample the actual observation \(x\) from the conditional distribution \(P(x|z)\). This essentially means that the high dimensional observation \(x\) can be explained semantically by the lower dimensional representation \(z\). <a href="https://arxiv.org/abs/1811.12359" rel="external nofollow noopener" target="_blank">Locatello et al</a>., suggest a few characteristics for a \(disentangled\) \(representation\) \(z\):</p> <ul> <li>contain all information in \(x\) in a compact and interpretable structure</li> <li>independent of the task being performed (eg. classification, etc)</li> <li>should be useful for (semi-)supervised learning of downstream tasks, transfer and few shot learning</li> <li>They should enable to integrate out nuisance factors, to perform interventions, and to answer counterfactual questions.</li> </ul> <p>The intuitive explanation adopted for disentangled representations is as follows: <em>a disentangled representation should separate the distinct, informative factors of variations in the data</em>. That is, changing one factor (\(z_i\)) in \(z\) should result in only a single factor in \(x\). In essence, if one feature in the representation changes it only affects one semantic feature of the observation. Let us consider the example of an image with an object. A <em>good</em> disentangled representation in this case would capture the location (xy-coordinates), shape, color and size as the <em>factors of variation</em>. This is a good disentangled representation since, changing on of the factors (let’s say the color) affects only the color and not the shape, size or location.</p> <p>This however is just a loose conceptual intuition behind the idea of disentangled representation. In fact, until recently there was no widely agreed upon solid definition for disentangled representations. Instead there were a number of different metrics proposed over the years that would capture these intuitions. Recently, <a href="https://arxiv.org/abs/1812.02230" rel="external nofollow noopener" target="_blank">Higgins, Amos et al.</a> proposed a formal definition of disentangled representations using the idea of symmetry transforms and from group and representation theory. This formalism helps in setting up a concrete definition for the problem being solved and helps in evaluating and understanding approaches to solve the problem. Their definition is as follows:</p> <p><strong><em>A vector representation is called a disentangled representation with respect to a particular decomposition of a symmetry group into subgroups, if it decomposes into independent subspaces, where each subspace is affected by the action of a single subgroup, and the actions of all other subgroups leave the subspace unaffected.</em></strong></p> <p>A symmetry transform of an object is a \(transformation\) that leaves certain properties of the object \(invariant\). For example, translation and rotation are symmetries of objects – an apple is still an apple whether it is placed on a table or in a bag, and whether it rolls on its side or remains upright. The set of such transformations forms the \(symmetry\) \(group\) and the effects of these transformations are the \(actions\) of the symmetry group on the world state(Note: this the underlying world state and not the observation \(x\)). The actions that change only a certain aspect of the world state while keeping others fixed is a \(disentangled\) \(group\) \(action\). So for example changing the horizontal position of apple only affects it’s horizontal position and not it’s vertical position or color, etc. Another thing we notice from this is that we can decompose this symmetry group into \(symmetry\) \(subgroups\). So in the example of the apple, horizontal transformation could be one such subgroup. Here the horizontal subspace is affected only by actions of the horizontal translation subgroup. So far we talked about the underlying abstract world state. To generalise to observations, we assume there is a generative process that generates the dataset of observations from a given set of underlying world states. In some situations, it is possible to find a composite mapping between the disentangled group actions in the abstract state space to the transformations in the vector space of the representation. In short, we can call a representation \(disentangled\) if the vector space of the representation can be decomposed into independent subspaces such that each subspace is only affected by a single symmetry subgroup, which in turn is a set of symmetry transformations that affect only a certain aspect of the world state. The paper decribes the formalism in further detail and also discusses link between the proposed definition and the currently generally accepted intuitive ideas about disentangled representations.</p> <p>One might question how are these representations useful? As we saw previously, disentangled representations capture independent features that describe a single aspect of the observation. This characteristic is useful in enabling generalisation to previously unobserved situations, since a model can extract meaningful information about the observation to understand it from the disentangled representation. Approches using disentangled representations have found a lot of successs in various tasks including <a href="https://arxiv.org/abs/1807.01521" rel="external nofollow noopener" target="_blank">curiousity driven exploration</a>, <a href="https://arxiv.org/abs/1811.04784" rel="external nofollow noopener" target="_blank">abstract reasoning</a>, <a href="https://arxiv.org/pdf/1707.03389.pdf" rel="external nofollow noopener" target="_blank">visual concept learning</a> and <a href="https://arxiv.org/pdf/1707.08475.pdf" rel="external nofollow noopener" target="_blank">domain adaptation in reinforcement learning</a>.</p> <h2 id="how-to-learn-these-disentangled-representations">How to learn these disentangled representations?</h2> <p>Learning disentangled representations is at it’s core a type of dimensionality reduction problem. The distinction here from other forms of dimensionality reduction is that there are certain restrictions on the vector space of the learned representation. Unsupervised learning of these representations is an interesting problem since it would allow models to learn from huge troves of available unlabelled data. Thus, there has been a lot of interest in the machine learning community to design unsupervised learning algorithms to learn these representations. Variants of variational autoencoders (proposed by <a href="https://arxiv.org/abs/1312.6114" rel="external nofollow noopener" target="_blank">Kingma and Welling</a> in 2013) have seen quite a lot of success in recent years in tackling this problem, and provide state of the art performance in unsupervised learning of disentangled representations. Variational Autoencoders can be seen as modelling the 2-step generative process described above. A specific prior \(P(z)\) is selected, and then the distribution \(P(x|z)\) is parameterized using a deep neural network. The goal is to infer good values of the latent variables given observed data, which is essentially computing the posterior \(P(z|x)\). This distribution \(P(z|x)\) is approximated using a variational distribution \(Q(z|x)\) which is also parametrized by a neural network. The representation is usually taken to be the mean of \(Q(z|x)\). We discuss the specifics of VAEs in later sections. Several models based on this, such as BetaVAE, FactorVAE, and AnnealedVAE among others, have been introduced to learn disentangled representations, and provide state-of-the-art performance.</p> <p>However, in their recent work, <a href="https://arxiv.org/pdf/1811.12359.pdf" rel="external nofollow noopener" target="_blank">Locatello et al.</a> perform a large systematic study of these models to evaluate the recent progress in the area. Their study had a few key findings:</p> <ul> <li>They found no empirical evidence that the considered models can be used to reliably learn disentangled representations in an unsupervised way, since random seeds and hyperparameters seem to matter more than the model choice. That is, even if a large number of models are trained with some of them being disentangled, these disentangled representations cannot be identified without access to ground-truth labels.</li> <li>Good hyperparameter values do not appear to consistently transfer across the datasets.</li> <li>They were not able to validate the assumption that disentanglement is useful for downstream tasks, e.g., few-shot learning with disentangled representations.</li> </ul> <p>In addition to these findings, they also present the <em>Impossibilty Result</em> which states the following: <em><strong>unsupervised learning of disentangled representations is impossible without inductive biases on both the data set and the models</strong></em>. So it is impossible to learn disentangled representations without making certain assumptions on the dataset and incorporating them in the model, which essentially restricts generalizability of models across datasets. They also propose observations for future research on the topic and to that end released the <a href="https://github.com/google-research/disentanglement_lib/" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">disentanglement_lib</code></a> with all the models used in their study to aid in future research in topic, along with the <a href="https://www.aicrowd.com/challenges/neurips-2019-disentanglement-challenge" rel="external nofollow noopener" target="_blank">NeurIPS 2019: Disentanglement Challenge</a> to accelerate research in the area.</p> <h2 id="variational-autoencoders">Variational Autoencoders</h2> <p>As discussed in the previous sections, we start by assuming a specific prior \(p(z)\) on the latent space, parametrizing the distribution \(p(x|z)\) using a neural network, and approximating the posterior \(p(z|x)\) with a neural network parameterized variational distribution \(q(z|x)\). Now we discuss the motivations behind this model and how we train these models.</p> <p><span>What we want the model to do is to learn how to generate the representation given the data as input, i.e compute \(p(z|x)\), and also the model should be able to generate the data given the latent representation (compute \(p(x|z)\)). We start by sampling \(z\) from the prior \(p(z)\). The likelihood of the data conditioned to latent variable \(z\) is \(p(x|z)\). The joint distribution \(p(x, z)\) can be decomposed as \(p(x,z) = p(x|z)p(z)\). Now at first glance calculating the posterior \(p(z|x)\) might seem straightforward using the Bayes rule: \(p(z|x) = \frac{p(x|z)p(z)}{p(x)}\)</span></p> <p><span>However, computing \(p(x)=\int p(x|z)p(z)dz\) is not computationally tractable. Thus, we approximate the posterior \(p(z|x)\) with a family of distributions \(q_\lambda (z|x)\) (here \(\lambda\) is used as an index for the distributions). Kullback-Leibler divergence(KL divergence) is used to measure how different a probability distribution is from another given probability distribution. We use this to evaluate how well \(q_\lambda (z|x)\) approximates \(p(z|x)\). Our goal would be to have the distributions be as similar as possible, so we minimize the KL-divergence.</span></p> \[\mathbb{KL}(q_\lambda (z|x)\ ||\ p(z|x)) = \mathbf{E}_q[\log q_\lambda (z|x)] - \mathbf{E}_q[\log p(x, z)] + \log p(x)\] <p>But we encounter \(p(x)\) once again. To get around this we use the ELBO (Evidence Lower Bound).</p> \[ELBO(\lambda) = \mathbf{E}_q[\log p(x, z)] - \mathbf{E}_q[\log q_\lambda (z|x)]\] <p>Thus from these two equations we get the following:</p> \[\log p(x) = ELBO(\lambda) + \mathbb{KL}(q_\lambda (z|x)\ ||\ p(z|x))\] <p>Since the Jensen inequality states that the KL divergence is always \(\geq 0\), KL-divergence can be minimized by maximizing ELBO (as \(p(x)\) doesn’t change). Maximizing the ELBO is computationally tractable, thus we can train the model with the objective of maximizing ELBO. Now, since no datapoint shares its latent \(z\) with the latent variable of another datapoint, we can decompose ELBO into a sum such that each term depends on one datapoint.</p> \[ELBO_i(\lambda)=\mathbf{E}_{q_\lambda} [\log p(x_i | z)] - \mathbb{KL}(q_\lambda (z|x_i) || p(z))\] <p>This value can be interpreted as follows: The first term is the reconstruction loss for the datapoints (i.e. get \(z\) from \(x\) and then obtain \(x'\) and compare \(x\) and \(x'\)) and the KL-divergence term acts as a sort of regularizer.</p> <p><span>As mentioned previously, the distrbutions can be parametrized by neural networks. So we start with the approximate posterior, which is also called encoder as it encodes the input data into the latent variable \(q_\theta (z|x, \lambda)\)(where \(\theta\) indicates the neural network weights), which outputs the \(\lambda\) for a given datapoint \(x\). As mentioned earlier \(\lambda\) is an index over the family of distrbutions \(q\), so we use \(\lambda\) to get the required distribution and sample the latent representation \(z\) from it. For example if we select a family of gaussians then \(\lambda\) would be the mean and variance of the distributions. Once we have \(z\) we obtain the reconstruction from the ‘decoder’, \(p_\phi (x|z)\). And the loss function is \(-ELBO\) which we can minimize using stochastic gradient descent. </span></p> <p><span>This was the general idea behind a variational autoencoder. Now to allow these models to learn disentangled representations, the general approach is to enforce a factorized aggregated posterior \(\int q(z|x)p(x)dx\) to encourage disentanglement. All of the approaches try to enforce this in some way by either modifying the regularizer or having additional objectives or by some architectural choices. </span></p> <h2 id="summary">Summary</h2> <p>In this post we discussed what are disentangled representations, what are autoencoders, and how we can use variational autoencoders to learn disentangled representations. In the accompanying notebook we demonstrate how to get started by building a custom VAE with the disentanglement_lib, evaluating it and visualising it. If you are interested in disentangled representations, do consider participating in the <a href="https://www.aicrowd.com/challenges/neurips-2019-disentanglement-challenge" rel="external nofollow noopener" target="_blank">NeurIPS 2019: Disentanglement Challenge</a>.</p> <h2 id="references">References</h2> <p>Locatello, Francesco et al. <a href="https://arxiv.org/abs/1811.12359" rel="external nofollow noopener" target="_blank">“Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations.”</a> ICML (2018).</p> <p>Higgins, Irina et al. <a href="https://arxiv.org/abs/1812.02230" rel="external nofollow noopener" target="_blank">“Towards a Definition of Disentangled Representations.”</a> ArXiv abs/1812.02230 (2018)</p> <p><a href="https://jaan.io/what-is-variational-autoencoder-vae-tutorial/" rel="external nofollow noopener" target="_blank">Tutorial - What is a variational autoencoder? - Jaan Alatosaar</a></p> <p><a href="https://ai.googleblog.com/2019/04/evaluating-unsupervised-learning-of.html" rel="external nofollow noopener" target="_blank">Google AI Blog: Evaluating the Unsupervised Learning of Disentangled Representations</a></p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib"></d-bibliography> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Moksh Jain. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: October 14, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>